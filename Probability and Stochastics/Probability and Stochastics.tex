\documentclass[fontset=none]{Notes}

\makeatletter
\DeclareRobustCommand{\em}{%
  \@nomath\em \if b\expandafter\@car\f@series\@nil
  \normalfont \else \bfseries \fi}
\makeatother

\usepackage{tikz-cd,wrapstuff}
\usepackage{fixdif,siunitx,tikz,nicematrix}
\usetikzlibrary{matrix,calc}

\input{font.def}

\usepackage[subscriptcorrection,nofontinfo,mtpbb,mtpfrak]{mtpro2}

\tikzcdset{
  arrow style=tikz,
  diagrams={>={Straight Barb[scale=0.8]}}
}

\allowdisplaybreaks[1]

\newlength{\mymathln}
\newcommand{\aligninside}[2]{
  \settowidth{\mymathln}{#2}
  \mathmakebox[\mymathln]{#1}
}

\DeclareMathOperator\Spec{Spec}
\DeclareMathOperator\im{im}
\DeclareMathOperator\nil{nil}
\DeclareMathOperator\rad{rad}
\DeclareMathOperator\Ann{Ann}
\DeclareMathOperator\Max{Max}
\DeclareMathOperator\GL{GL}
\DeclareMathOperator\End{End}
\DeclareMathOperator\Int{Int}
\DeclareMathOperator\Tor{Tor}
\DeclareMathOperator\Frac{Frac}
\DeclareMathOperator\Tr{Tr}
\DeclareMathOperator\Hom{Hom}
\DeclareMathOperator\Leb{Leb}
\DeclareMathOperator\supp{supp}
\DeclareMathOperator\Id{Id}
\DeclareMathOperator\rk{rank}
\DeclareMathOperator\var{var}
\DeclareMathOperator\cov{cov}
\DeclareMathOperator\card{card}
\DeclareMathOperator\coker{coker}
\DeclareMathOperator\vol{vol}
\undef\Re
\undef\Im 
\DeclareMathOperator\Re{Re}
\DeclareMathOperator\Im{Im}

\newcommand{\ideal}[1]{\mathfrak{#1}}
\newcommand{\mat}[1]{\mathbold{#1}}
\newcommand{\matup}[1]{\mathbf{#1}}
\newcommand{\uline}{\underline{\hphantom{X}}}
\newcommand{\abs}[1]{\left|#1\right|}
\newcommand{\ulim}[1][]{\lim_{#1}\mathrel{\uparrow}}
\newcommand{\dlim}[1][]{\lim_{#1}\mathrel{\downarrow}}
\newcommand{\indicator}[1]{\mathbold 1_{#1}}
\newcommand{\alev}[1]{\text{$#1$ a.e.}}
\newcommand{\alsu}[1]{\text{$#1$ a.s.}}
\newcommand{\norm}[1]{\left\Vert#1\right\Vert}

\newcommand{\idf}{\mathbold 1}

\usepackage{enumitem}

\setlist[enumerate]{nosep}

%\DeclareMathAlphabet\mathcal{OMS}{cmsy}{m}{n}

\newlength\stextwidth
\newcommand\makesamewidth[3][c]{%
  \settowidth{\stextwidth}{#2}%
  \makebox[\stextwidth][#1]{#3}%
}



\begin{document}

\frontmatter

\tableofcontents

\mainmatter


\part{测度论}

\include{chapters/ch1/measurable space}

\include{chapters/ch2/integral}

\include{chapters/ch3/construction of measure}

\include{chapters/ch4/L^p space}

\include{chapters/ch5/product measure}

\part{概率论}

\include{chapters/ch8/probability}


\chapter{独立性}

\section{独立事件}

在本章中，我们考虑概率空间 $(\Omega,\mathcal{A},\mathbb{P})$。如果 
$A,B\in \mathcal{A}$ 且
\[
  \mathbb{P}(A\cap B)=\mathbb{P}(A)\mathbb{P}(B),  
\]
那么我们说 $A$ 和 $B$ 是\emph{独立的}。
如果 $\mathbb{P}(B)>0$，我们定义条件概率
\[
  \mathbb{P}(A|B)=\frac{\mathbb{P}(A\cap B)}{\mathbb{P}(B)}.
\]
此时 $A$ 和 $B$ 独立等价于 $\mathbb{P}(A|B)=\mathbb{P}(A)$。

\begin{definition}
  如果对于 $\{1,\dots,n\}$
  的任意子集 $\{j_1,\dots,j_p\}$ 都有
  \[
    \mathbb{P}(A_{j_1}\cap \cdots\cap A_{j_p})
    =\mathbb{P}(A_{j_1})\cdots \mathbb{P}(A_{j_p}),
  \]
  那么我们说 $n$ 个事件 $A_1,\dots,A_n$ 是独立的。
\end{definition}

\begin{proposition}\label{prop:independence by sigma algebra}
  $n$ 个事件 $A_1,\dots,A_n$ 独立当且仅当
  \[
    \mathbb{P}(B_1\cap\cdots\cap B_n)=\mathbb{P}(B_1)\cdots \mathbb{P}(B_n),
  \]
  其中 $B_i\in\sigma(A_i)=\{\emptyset,A,A^c,\Omega\}$。
\end{proposition}



\section{$\sigma$-域和随机变量的独立性}

如果 $\mathcal{B}\subseteq \mathcal{A}$ 是一个 $\sigma$-域，那么我们说
$\mathcal{B}$ 是 $\mathcal{A}$ 的\emph{子 $\mathbold{\sigma}$-域}。我们可以认为
子 $\sigma$-域 $\mathcal{B}$ 反映了概率空间的部分信息，即 $\mathcal{B}$ 中
发生的事件。例如，如果 $\mathcal{B}=\sigma(X)$，$X$ 是随机变量，那么
$\mathcal{B}$ 反映了 $X$ 的值的信息。这暗示了子 $\sigma$-域的独立性的概念：
我们希望两个子 $\sigma$-域 $\mathcal{B}$ 和 $\mathcal{B}'$ 是独立的当且仅当
它们中的任意两个事件都是独立的。

\begin{definition}
  令 $\mathcal{B}_1,\dots,\mathcal{B}_n$ 是 $\mathcal{A}$ 的 $n$ 个
  $\sigma$-子域，我们说 $\mathcal{B}_1,\dots,\mathcal{B}_n$ 是独立的，如果
  对于任意 $A_1\in \mathcal{B}_1,\dots,A_n\in \mathcal{B}_n$，都有
  \[
    \mathbb{P}(A_1\cap\cdots\cap A_n)=\mathbb{P}(A_1)\cdots \mathbb{P}(A_n).  
  \]
\end{definition}

令 $X_1,\dots,X_n$ 分别是值在 $(E_1,\mathcal{E}_1),\dots,(E_n,\mathcal{E}_n)$
中的随机变量，我们说 $X_1,\dots,X_n$ 是独立的当且仅当
$\sigma(X_1),\dots,\sigma(X_n)$ 是独立的。这等价于
任取 $F_1\in \mathcal{E}_1,\dots,F_n\in \mathcal{E}_n$ 有
\[
  \mathbb{P}(\{X_1\in F_1\}\cap\cdots\cap\{X_n\in F_n\})  
  =\mathbb{P}(X_1\in F_1)\cdots \mathbb{P}(X_n\in F_n).
\]

有时候考虑一族随机变量之间的独立性也是有用的。对于两族随机变量 $(X_i)_{i\in I}$
和 $(Y_j)_{j\in J}$，如果 $\sigma$-域 $\sigma((X_i)_{i\in I})$ 和 $\sigma((Y_j)_{j\in J})$
是独立的，那么我们说这两族随机变量是独立的。注意到这比任意 $X_i$ 与 $Y_j$ 独立要更强。

\begin{remark}
  (1) 如果 $\mathcal{B}_1,\dots,\mathcal{B}_n$ 是 $\mathcal{A}$ 的 $n$ 个独立的 $\sigma$-子域，
  并且 $X_i$ 是 $\mathcal{B}_i$-可测的随机变量，那么 $X_1,\dots,X_n$ 是独立的。这是因为
  $X_i$ 是 $\mathcal{B}_i$-可测的就表明 $\sigma(X_i)\subseteq \mathcal{B}_i$。

  (2) $n$ 个事件 $A_1,\dots,A_n$ 是独立的当且仅当 $\sigma$-域 $\sigma(A_1),\dots,\sigma(A_n)$
  是独立的(\autoref{prop:independence by sigma algebra})。
\end{remark}


\begin{theorem}\label{thm:independence by product measure}
  令 $X_1,\dots,X_n$ 分别是值在 $(E_1,\mathcal{E}_1),\dots,(E_n,\mathcal{E}_n)$
  中的随机变量。那么 $X_1,\dots,X_n$ 是独立的当且仅当 $(X_1,\dots,X_n)$
  的分布是 $X_1,\dots,X_n$ 的分布的乘积测度，即
  \[
    \mathbb{P}_{(X_1,\dots,X_n)}=\mathbb{P}_{X_1}\otimes\cdots
    \otimes \mathbb{P}_{X_n}.  
  \]
  此外，我们有
  \[
    \mathbb{E}\biggl[\prod_{i=1}^n f_i(X_i)\biggr] =\prod_{i=1}^n \mathbb{E}[f_i(X_i)],
  \]
  其中 $f_i$ 是 $(E_i,\mathcal{E}_i)$ 上的非负可测函数。
\end{theorem}
\begin{proof}
  令 $F_i\in \mathcal{E}_i$，$X_1,\dots,X_n$ 独立当且仅当
  \[
    \mathbb{P}(\{X_1\in F_1\}\cap\cdots\cap\{X_n\in F_n\})  
    =\mathbb{P}(X_1\in F_1)\cdots \mathbb{P}(X_n\in F_n),
  \]
  这表明
  \[ 
    \mathbb{P}_{(X_1,\dots,X_n)}(F_1\times\cdots\times F_n)
    =\mathbb{P}_{X_1}(F_1)\cdots \mathbb{P}_{X_n}(F_n).
  \]
  所以 $\mathbb{P}_{(X_1,\dots,X_n)}$ 就是乘积测度 
  $\mathbb{P}_{X_1}\otimes\cdots\otimes \mathbb{P}_{X_n}$。

  记 $\pi_i:E_1\times \cdots\times E_n\to E_i$ 为投影，根据 Fubini 定理，有
  \begin{align*}
    \mathbb{E}\biggl[\prod_{i=1}^n f_i(X_i)\biggr]&=
    \int_{E_1\times\cdots \times E_n}\prod_{i=1}^n f_i\circ\pi_i
    \d\mathbb{P}_{(X_1,\dots,X_n)}\\
    &=\prod_{i=1}^n \int_{E_i} f_i(x_i) \mathbb{P}_{X_i}(\d x_i)\\
    &=\prod_{i=1}^n \mathbb{E}[f_i(X_i)].\qedhere
  \end{align*}
\end{proof}
\begin{remark}
  该定理中 $f_i$ 也可以是任意符号，此时如果 $\mathbb{E}[|f_i(X_i)|]<\infty$，
  也即 $f_i\in \mathcal{L}^1(E_i,\mathcal{E}_i,\mathbb{P}_{X_i})$，那么
  定理的结论依然成立。只需要注意到
  \[
    \mathbb{E}\biggl[
      \prod_{i=1}^n |f_i(X_i)|
    \biggr]=\prod_{i=1}^n \mathbb{E}[|f_i(X_i)|]<\infty.
  \]
  特别地，如果 $X_1,\dots,X_n$ 是独立的实值随机变量且 $X_i\in L^1$，
  那么 $X_1\cdots X_n\in L^1$ 且
  \[
    \mathbb{E}[X_1\cdots X_n]=\prod_{i=1}^n \mathbb{E}[X_i].
  \]
  需要注意一般情况下 $L^1$ 中的随机变量的积不一定还在 $L^1$ 中。
\end{remark}

\autoref{thm:independence by product measure} 展示了如何构造有限多个独立的随机变量。
考虑实值随机变量的情况。令 $\mu_1,\dots,\mu_n$ 是 $\mathbb{R}$ 上的 $n$ 个
概率测度。首先我们可以构造一个值在 $\mathbb{R}^n$ 中的随机变量 $Y=(Y_1,\dots,Y_n)$
使得其有分布律 $\mu_1\otimes\cdots\otimes \mu_n$ (比如令 $\Omega=\mathbb{R}^n$，
$\mathcal{A}=\mathcal{B}(\mathbb{R}^n)$，$\mu_1\otimes\cdots\otimes \mu_n$
是概率测度，那么随机变量 $Y(\omega)=\omega$ 即符合要求)。然后 \autoref{thm:independence by product measure}
表明分量 $Y_1,\dots,Y_n$ 是分别拥有分布律 $\mu_1,\dots,\mu_n$ 的独立实值随机变量。

\begin{corollary}
  如果 $X_1,X_2$ 是 $L^2$ 中的两个独立实值随机变量，那么 $\cov(X_1,X_2)=0$。
\end{corollary}




\begin{corollary}\label{coro:independence by pdf}
  令 $X_1,\dots,X_n$ 是实值随机变量。
  \begin{enumerate}
    \item 假设 $X_i$ 有密度 $p_i$ 并且 $X_1,\dots,X_n$ 是独立的，那么
    $(X_1,\dots,X_n)$ 有密度
    \[
      p(x_1,\dots,x_n)=\prod_{i=1}^n p_i(x_i).  
    \]
    \item 反之，假设 $(X_1,\dots,X_n)$ 有密度 $p$，并且
    $p$ 可以表达为
    \[
    p(x_1,\dots,x_n)=\prod_{i=1}^n q_i(x_i),  
    \]
    其中 $q_i$ 是 $\mathbb{R}$ 上的非负可测函数。那么 $X_1,\dots,X_n$
    是独立的并且 $X_i$ 有密度 $p_i=C_iq_i$，其中 $C_i>0$ 为常数。
  \end{enumerate}
\end{corollary}
\begin{proof}
  (1) $X_i$ 有密度 $p_i$ 表明 $\mathbb{P}_{X_i}(\d x)=p_i(x)\d x$，
  $X_1,\dots,X_n$ 独立表明
  \begin{align*}
    \mathbb{P}_{(X_1,\dots,X_n)}(A)&=
    \mathbb{P}_{X_1}\otimes\cdots\otimes \mathbb{P}_{X_n}(A)
    =\int_{\mathbb{R}^n} \indicator{A} \d \mathbb{P}_{X_1}\otimes\cdots\otimes \mathbb{P}_{X_n}
    \\
    &=\int_{\mathbb{R}}\cdots \int_{\mathbb{R}}\indicator{A}(x_1,\dots,x_n)
    \mathbb{P}_{X_1}(\d x_1)\cdots \mathbb{P}_{X_n}(\d x_n) \\
    &=\int_{\mathbb{R}}\cdots \int_{\mathbb{R}}\indicator{A}(x_1,\dots,x_n)
    \prod_{i=1}^n p_i(x_i)
    \d x_1\cdots \d x_n\\
    &=\int_{\mathbb{R}^n} \indicator{A}\prod_{i=1}^n p_i \d \lambda
    =\int_A \prod_{i=1}^np_i(x_i) \d x_1\cdots\d x_n,
  \end{align*}
  这就表明 
  \[
    p(x_1,\dots,x_n)=\prod_{i=1}^n p_i(x_i).  
  \]

  (2) 根据 \autoref{prop:margin pdf}，有
  \[
    p_i(x_i)=\int_{\mathbb{R}^{n-1}}p(x_1,\dots,x_n)\d x_1\cdots \d x_{i-1}
    \d x_{i+1}\cdots\d x_n
    =q_i(x_i)\prod_{j\neq i}\int_{\mathbb{R}}q_j(x_j)\d x_j,
  \]
  故 $p_i=C_iq_i$。此时
  \begin{align*}
    p(x_1,\dots,x_n)=\prod_{i=1}^n q_i(x_i)
    =\prod_{i=1}^n \frac{1}{C_i}p_i(x_i),
  \end{align*}
  两边积分可知 $\prod_{i=1}^n C_i=1$，所以
  \[
    p(x_1,\dots,x_n)=\prod_{i=1}^n p_i(x_i),  
  \]
  这就表明 $\mathbb{P}_{(X_1,\dots,X_n)}=\mathbb{P}_{X_1}\otimes\cdots \mathbb{P}_{X_n}$，
  即 $X_1,\dots,X_n$ 独立。
\end{proof} 

\begin{example}
  令 $U$ 是服从参数 $1$ 的指数分布的随机变量，$V$ 是服从 $[0,1]$ 上
  的均匀分布的随机变量，假设 $U,V$ 是独立的，记
  \[
    X=\sqrt{U}\cos(2\pi V),\quad Y=\sqrt{U}\sin(2\pi V),  
  \]
  证明 $X,Y$ 是独立的随机变量。
\end{example}
\begin{proof}
  任取非负可测函数 $\varphi:\mathbb{R}^2\to \mathbb{R}$，有
  \begin{align*}
    \mathbb{E}[\varphi(X,Y)]
    &=\mathbb{E}
    \bigl[\varphi\bigl(\sqrt{U}\cos(2\pi V),\sqrt{U}\sin(2\pi V)\bigr)\bigr]\\
    &=\int_{\mathbb{R}^2}\varphi\bigl(\sqrt{u}\cos(2\pi v),\sqrt{u}\sin(2\pi v)\bigr)
    \d \mathbb{P}_{(U,V)}\\
    &=\int_{\mathbb{R}}\int_{\mathbb{R}}\varphi\bigl(\sqrt{u}\cos(2\pi v),\sqrt{u}\sin(2\pi v)\bigr)
      e^{-u}\indicator{[0,\infty)}(u)\indicator{[0,1]}(v)\d u\d v\\
    &=\int_{0}^\infty\int_0^1\varphi\bigl(\sqrt{u}\cos(2\pi v),\sqrt{u}\sin(2\pi v)\bigr)
    e^{-u}\d u\d v \\
    &=\frac{1}{\pi}\int_0^\infty\int_0^{2\pi}
    \varphi(r\cos\theta,r\sin\theta)re^{-r^2}\d r\d\theta\\
    &=\frac{1}{\pi}\int_{\mathbb{R}^2}\varphi(x,y)e^{-x^2-y^2}\d x\d y.
  \end{align*}
  这表明 $(X,Y)$ 有概率密度 $p(x,y)=\pi^{-1}\exp(-x^2-y^2)=\pi^{-1}\exp(-x^2)\exp(-y^2)$，
  根据 \autoref{coro:independence by pdf}，这表明 $X,Y$
  是独立的。
\end{proof}

\section{Borel-Cantelli 引理}

回顾集合极限的定义：如果 $(A_n)_{n\in \mathbb{N}}$ 是一列集合，
我们记
\[
  \limsup A_n=\bigcap_{n=1}^\infty \bigcup_{k=n}^\infty A_k,  
\]
不难发现点 $\omega\in\limsup A_n$ 当且仅当存在无限多个
$n$ 使得 $\omega\in A_n$。注意到
\ref{lemma:liminf and limsup ineq} 告诉我们
$\mathbb{P}(\limsup A_n)\geq \limsup \mathbb{P}(A_n)$。

\begin{lemma}
  令 $(A_n)_{n\in \mathbb{N}}$ 是一列事件。
  \begin{enumerate}
    \item 如果 $\sum_{n\in \mathbb{N}}\mathbb{P}(A_n)<\infty$，那么
    \[
      \mathbb{P}(\limsup A_n)=0,  
    \]
    \item 如果 $\sum_{n\in \mathbb{N}}\mathbb{P}(A_n)=\infty$，
    事件 $A_n$ 是独立的，那么
    \[
      \mathbb{P}(\limsup A_n)=1.  
    \]
  \end{enumerate}
\end{lemma}

\paragraph{两个应用}
(2) 我们令
\[
  (\Omega,\mathcal{A},\mathbb{P})=\bigl([0,1),\mathcal{B}([0,1)),\lambda\bigr) ,
\]
其中 $\lambda$ 表示 Lebesgue 测度。对于每个 $n\in \mathbb{N}$，令
\[
  X_n(\omega)=\lfloor 2^n\omega\rfloor-2\lfloor 2^{n-1}\omega\rfloor,
\]
其中 $\lfloor x\rfloor$ 表示向下取整。那么 $X_n(\omega)\in\{0,1\}$
并且容易验证对于任意 $\omega\in [0,1)$ 有
\[
  0\leq\omega-\sum_{k=1}^nX_k(\omega)2^{-k}<2^{-n}.  
\]
这表明
\[
  \omega=\sum_{k=1}^\infty X_k(\omega)2^{-k}.  
\]

\section{独立随机变量的和}

\begin{proposition}[强大数定律]\label{prop:strong law}
  令 $(X_n)_{n\in \mathbb{N}}$ 是一列独立同分布的实值随机变量，
  若 $\mathbb{E}[X_1^4]<\infty$，那么我们几乎肯定有
  \[
    \frac{1}{n}(X_1+\cdots+X_n)\xrightarrow[n\to\infty]{} \mathbb{E}[X_1].
  \]
\end{proposition}


\section{Poisson 过程}\label{sec:poisson}

在本节，我们固定一个参数 $\lambda>0$，令 $U_1,U_2,\dots$ 是
一列独立同分布的随机变量，它们都服从参数 $\lambda$ 的指数分布，
即有概率密度 $\lambda e^{-\lambda x}\indicator{\mathbb{R}_+}$。
令
\[
  T_n=U_1+U_2+\cdots+U_n.  
\]
对于任意实数 $t\geq 0$，令
\[
  N_t=\sum_{n=1}^\infty \indicator{\{T_n\leq t\}}=\sup\{n\in \mathbb{N}\,|\,T_n\leq t\}  .
\]
约定 $\sup\emptyset =0 $。\autoref{prop:strong law}
告诉我们在 $n\to\infty$ 的时候，$T_n\to\infty \alsu{}$。
因此，使得 $(T_n)_{n\in \mathbb{N}}$ 有界的 $\omega\in\Omega$ 的集合构成一个零测集，
除开这个零测集，对于任意 $t\geq 0$，我们都有 $N_t<\infty$。类似地，因为
随机变量 $U_i$ 几乎处处是正值，我们可以假设对于每个 $\omega\in\Omega$ 都有
$0<T_1(\omega)<T_2(\omega)<\cdots$。

固定 $\omega$，函数 $t\mapsto N_t(\omega)$ 在 $0$ 处为零、单调递增且右连续，此外
其每次以大小为 $1$ 的幅度增加。这个函数我们称为计数函数。在 $t\to\infty$
的时候有 $N_t\to\infty$。

\begin{definition}
  随机变量族 $(N_t)_{t\geq 0}$ 被称为参数 $\lambda$ 的 Poisson 过程。
\end{definition}

泊松过程经常用于应用概率模型中，例如在排队论中，$N_t$ 表示在时间 $t$ 之前到达
服务器的客户数量。选择指数分布来模拟两个连续到达的客户之间的时间段与指数分布缺乏记忆的特性有关。
粗略地说，该属性表示，对于任何给定时间 $t \geq 0$，$t$ 与客户下一次到达之间的时间始终
具有相同的分布，与时间 $t$ 之前发生的情况无关。

\begin{proposition}
  对于每个 $n\geq 1$，$T_n$ 服从 Gamma 分布 $\Gamma(n,\lambda)$，
  密度为
  \[
    p(x)=\frac{\lambda^n}{(n-1)!}x^{n-1}e^{-\lambda x}\indicator{\mathbb{R}_+}(x).  
  \]
  对于每个 $t> 0$，$N_t$ 服从参数 $\lambda t$ 的 Poisson 分布：
  \[
    \mathbb{P}(N_t=k)=\frac{(\lambda t)^k}{k!}e^{-\lambda t},
    \quad \forall k\in \mathbb{N} . 
  \]
\end{proposition}
\begin{proof}
  注意到参数 $\lambda$ 的指数分布就是 Gamma 分布 $\Gamma(1,\lambda)$。
  我们首先证明若 $X$ 服从分布 $\Gamma(a,\lambda)$，$Y$
  服从分布 $\Gamma(b,\lambda)$，且 $X,Y$ 独立，那么 $X+Y$
  服从分布 $\Gamma(a+b,\lambda)$。
  那么
  \begin{align*}
    \mathbb{E}[\varphi(X+Y)]&=\int_{\mathbb{R}^2}
    \varphi(x+y)p_a(x)p_b(y)\d x\d y\\
    &=\int_{\mathbb{R}}\varphi(z)\left(\int_{\mathbb{R}}p_a(x)p_b(z-x)\d x\right)\d z\\
    &=\int_0^\infty\varphi(z)\left(\int_{0}^z
    \frac{\lambda^{a+b}}{\Gamma(a)\Gamma(b)}x^{a-1}
    (z-x)^{b-1}e^{-\lambda z}\d x\right) \d z\\
    &=\int_0^\infty \frac{\lambda^{a+b}e^{-\lambda z}z^{a+b-1}}{\Gamma(a)\Gamma(b)}
    \varphi(z)\left(\int_0^1 x^{a-1}(1-x)^{b-1}\d x\right)\d z\\
    &=\int_0^\infty \varphi(z)\frac{\lambda^{a+b}}{\Gamma(a+b)}
    z^{a+b-1}e^{-\lambda z}\d z,
  \end{align*}
  这就表明 $X+Y$ 服从分布 $\Gamma(a+b,\lambda)$。由于
  $T_n=U_1+\cdots+U_n$，所以 $T_n$ 服从分布 $\Gamma(n,\lambda)$。

  对于 $k\geq 1$，有
  \begin{align*}
    \mathbb{P}(N_t=k)&=\mathbb{P}(T_k\leq t< T_{k+1})\\
    &=\mathbb{P}(T_{k}\leq t)-\mathbb{P}(T_{k+1}\leq t)\\
    &=\int_0^t \frac{\lambda^k}{(n-1)!}x^{k-1}e^{-\lambda x}\d x
    -\int_0^t \frac{\lambda^{k+1}}{k!}x^{k}e^{-\lambda x}\d x\\
    &=\frac{(\lambda t)^k}{k!}e^{-\lambda t}.
  \end{align*}
  对于 $k=0$ 的时候，有
  $\mathbb{P}(N_t=0)=\mathbb{P}(T_1>t)=e^{-\lambda t}$。
  这就表明 $N_t$ 服从参数 $\lambda t$ 的 Poisson 分布。
\end{proof}

我们现在将陈述有关 Poisson 过程的第一个重要结果。我们需要引入
给定事件的条件概率的概念（更多关于条件的内容将在 \autoref{chap:condition} 中找到）。
如果 $B\in \mathcal{A}$ 使得 $\mathbb{P}(B)>0$，我们定义 $(\Omega,\mathcal{A})$
上的一个新的概率测度：已知 $B$ 的条件概率，记为 $\mathbb{P}(\cdot\,|\, B)$。
对于每个 $A\in \mathcal{A}$，其满足
\[
  \mathbb{P}(A|B)=\frac{\mathbb{P}(A\cap B)}{\mathbb{P}(B)}.  
\]
对于每个非负随机变量 $X$，$X$ 在 $\mathbb{P}(\cdot\,|\, B)$ 下的期望
记为 $\mathbb{E}[X|B]$，容易看出
\[
  \mathbb{P}(A|B)=  \frac{\mathbb{P}(A\cap B)}{\mathbb{P}(B)}
  =\int_{A}\frac{\indicator{B}}{\mathbb{P}(B)}\d \mathbb{P},
\]
所以 $\mathbb{P}(\cdot\,|\, B)$ 相对于 $\mathbb{P}$ 有密度 $\indicator{B}/\mathbb{P}(B)$，
故
\[
  \mathbb{E}[X|B]=\int_{\Omega} X(\omega) \mathbb{P}(\d\omega|B)
  = \int_\Omega X(\omega)\frac{\indicator{B}(\omega)}{\mathbb{P}(B)}
  \mathbb{P}(\d\omega)=\frac{\mathbb{E}[X\indicator{B}]}{\mathbb{P}(B)}. 
\]

\begin{proposition}
  令 $t>0$，$n\in \mathbb{N}$。在条件概率 $\mathbb{P}(\cdot\,|\, N_t=n)$
  下，随机变量 $(T_1,\dots,T_n)$ 有密度
  \[
    \frac{n!}{t^n}\indicator{\{0<s_1<s_2<\cdots<s_n<t\}}  .
  \]
  此外，在条件概率 $\mathbb{P}(\cdot\,|\, N_t=n)$ 下，随机变量
  $T_{n+1}-t$ 服从参数 $\lambda$ 的指数分布并且独立于 $(T_1,\dots,T_n)$。
\end{proposition}

现在我们陈述关于 Poisson 过程的一个非常重要的定理。

\begin{theorem}
  令 $t>0$，对于每个 $r\geq 0$，令
  \[
    N_r^{(t)}=N_{t+r}-N_t.  
  \]
  随机变量族 $(N_r^{(t)})_{r\geq 0}$ 仍然是参数 $\lambda$
  的 Poisson 过程，并且与 $(N_r)_{0\leq r\leq t}$ 独立。
\end{theorem}
\begin{remark}[直观解释]
  如果我们将 Poisson 过程的跳跃时间解释为客户到达服务器的时间，
  则该定理意味着如果有一个在时间 $t > 0$ 到达的观察者，其记录 $t$
  之后客户的到达时间，看到（在分布的意义下）的情况与他在时间 $0$ 到达
  的时候一样，并且了解时间 $0$ 和 $t$ 之间客户的到达时间不会给他提供
  有关时间 $t$ 之后客户到达情况的信息。这可以被视为所谓“Markov 性质”的
  一个方面。
\end{remark}

\begin{corollary}
  令 $t_0=0\leq t_1\leq\cdots\leq t_k$，随机变量 $N_{t_1},N_{t_2}-N_{t_1},
  \dots,N_{t_k}-N_{t_{k-1}}$ 是独立的，并且，对于每个 $1\leq j\leq k$，
  $N_{t_j}-N_{t_{j-1}}$ 服从参数 $\lambda(t_j-t_{j-1})$ 的 Poisson 分布。
\end{corollary}


\chapter{随机变量的收敛}


\chapter{条件}\label{chap:condition}

\section{离散条件}

本章中考虑概率空间 $(\Omega,\mathcal{A},\mathbb{P})$。我们已经在
\autoref{sec:poisson} 中提到了，如果 $B\in \mathcal{A}$ 是
一个概率为正的事件，我们可以定义 $(\Omega,\mathcal{A})$ 上的一个
新的概率测度：对于 $A\in \mathcal{A}$，定义
\[
  \mathbb{P}(A|B)=\frac{\mathbb{P}(A\cap B)}{\mathbb{P}(B)}.  
\]
概率测度 $A\mapsto \mathbb{P}(A|B)$ 被称为给定 $B$ 下的条件概率。
类似地，对于每个非负随机变量 $X$，或者 $X\in L^1(\Omega,\mathcal{A},\mathbb{P})$，
定义给定 $B$ 下的 $X$ 的\emph{条件期望}为
\[
  \mathbb{E}[X|B]=\frac{\mathbb{E}[X\indicator{B}]}{\mathbb{P}(B)}.  
\]

现在我们定义已知一个离散随机变量下的条件期望。考虑一个离散随机变量
$Y$，取值在可数空间 $E$ 中（$\sigma$-域为幂集）。令
$E'=\{y\in E\,|\, \mathbb{P}(Y=y)>0\}$。如果 $X\in L^1(\Omega,\mathcal{A},\mathbb{P})$，
那么对于每个 $y\in E'$，有
\[
  \mathbb{E}[X|Y=y]=\frac{\mathbb{E}[X\indicator{\{Y=y\}}]}{\mathbb{P}(Y=y)}.
\]

\begin{definition}
  令 $X\in L^1(\Omega,\mathcal{A},\mathbb{P})$，定义已知 $Y$ 下
  的 $X$ 的条件期望为一个\emph{随机变量}
  \[
    \mathbb{E}[X|Y]=\varphi(Y),  
  \]
  其中 $\varphi:E\to \mathbb{R}$ 为
  \[
    \varphi(y)=\begin{cases}
      \mathbb{E}[X|Y=y] & y\in E',\\
      0 & y\in E\smallsetminus E'.
    \end{cases}
  \] 
\end{definition}
\begin{remark}
  定义中 $y\in E \smallsetminus E'$ 时 $\varphi(y)$ 的取值
  是无关紧要的，因为我们可以证明这样的情况仅仅构成一个零测集：
  \[
    \mathbb{P}(Y\in E \smallsetminus E')=
    \sum_{y\in E \smallsetminus E'}\mathbb{P}(Y=y)
    =0.
  \]
\end{remark}

与相对于一个事件的条件期望相比，需要注意 $\mathbb{E}[X|Y]$
是一个 $\Omega\to \mathbb{R}$ 的\emph{随机变量}，其几乎肯定满足
\[
  \mathbb{E}[X|Y](\omega)=\mathbb{E}[X|Y=Y(\omega)].  
\]

\begin{proposition}
  令 $X\in L^1(\Omega, \mathcal{A},\mathbb{P})$，我们有
  $\mathbb{E}\bigl[\bigl|\mathbb{E}[X|Y]\bigr|\bigr]\leq \mathbb{E}[|X|]$，
  这表明 $\mathbb{E}[X|Y]\in L^1(\Omega,\mathcal{A},\mathbb{P})$。
  此外，对于任意有界的 $\sigma(Y)$-可测的实值随机变量 $Z$，
  有
  \[
    \mathbb{E}[ZX]=\mathbb{E}\bigl[Z \mathbb{E}[X|Y]\bigr]  .
  \]
\end{proposition}

\section{条件期望的定义}

\subsection{可积随机变量}

下面的定理提供了关于一个子 $\sigma$-域的可积随机变量的条件期望
的定义。

\begin{theorem}\label{thm:conditioning variable}
  令 $\mathcal{B}$ 是 $\mathcal{A}$ 的一个子 $\sigma$-域，$X\in L^1(\Omega,\mathcal{A},\mathbb{P})$。
  那么 $L^1(\Omega,\mathcal{A},\mathbb{P})$ 中存在唯一的随机变量
  $\mathbb{E}[X| \mathcal{B}]$，使得
  \[
    \forall B\in \mathcal{B},\quad
    \mathbb{E}[X \indicator{B}]=\mathbb{E}\bigl[\mathbb{E}[X| \mathcal{B}]\indicator{B}\bigr]  .
  \]
  更一般地，对于每个有界的 $\mathcal{B}$-可测的实值随机变量 $Z$，
  有
  \[
    \mathbb{E}[XZ]=\mathbb{E}\bigl[\mathbb{E}[X| \mathcal{B}]Z\bigr]  .
  \]
  如果 $X\geq 0$，那么我们几乎肯定有 $\mathbb{E}[X| \mathcal{B}]\geq 0$。
\end{theorem}

特别地，如果 $\mathcal{B}=\sigma(Y)$ 是随机变量 $Y$ 生成的 $\sigma$-域，
我们在写法上不区分
\[
  \mathbb{E}[X| \mathcal{B}] = \mathbb{E}[X|\sigma(Y)]
  =\mathbb{E}[X|Y].
\]
这与前文离散情况下的定义是不冲突的。

\begin{proposition}[条件期望的性质]
  \mbox{}
  \begin{enumerate}
    \item 如果 $X\in L^1(\Omega,\mathcal{A},\mathbb{P})$
    并且 $X$ 是 $\mathcal{B}$-可测的，那么
    $\mathbb{E}[X|\mathcal{B}]=X$。
    \item $L^1(\Omega,\mathcal{A},\mathbb{P})$
    上的映射 $X\mapsto \mathbb{E}[X| \mathcal{B}]$
    是线性映射。
    \item 如果 $X\in L^1(\Omega,\mathcal{A},\mathbb{P})$，
    那么 $\mathbb{E}\bigl[\mathbb{E}[X| \mathcal{B}]\bigr]=\mathbb{E}[X]$。
    \item 如果 $X\in L^1(\Omega,\mathcal{A},\mathbb{P})$，那么
    $|\mathbb{E}[X|\mathcal{B}]|\leq \mathbb{E}\bigl[|X|\bigm| \mathcal{B}\bigr]\alsu{}$，
    因此 $\mathbb{E}\bigl[\bigl|\mathbb{E}[X|\mathcal{B}]\bigr|\bigr]\leq \mathbb{E}[|X|]$。
    因此映射 $X\mapsto \mathbb{E}[X|\mathcal{B}]$ 是 $L^1(\Omega,\mathcal{A},\mathbb{P})$
    上的压缩映射。
    \item 如果 $X,X'\in L^1(\Omega,\mathcal{A},\mathbb{P})$ 并且
    $X\geq X'$，那么 $\mathbb{E}[X|\mathcal{B}]\geq \mathbb{E}[X'|\mathcal{B}]\alsu{}$。
  \end{enumerate}
\end{proposition}

\section{条件期望的具体性质}

\begin{proposition}[嵌套 $\sigma$-域]\label{prop:nested sigma field}
  令 $\mathcal{B}_1,\mathcal{B}_2$ 是 $\mathcal{A}$ 的两个子 $\sigma$-域且
  $\mathcal{B}_1\subseteq \mathcal{B}_2$。那么对于任意非负（可积）随机变量 $X$，我们有
  \[
    \mathbb{E}\bigl[\mathbb{E}[X|\mathcal{B}_2]\bigm| \mathcal{B}_1\bigr]=
    \mathbb{E}[X|\mathcal{B}_1].
  \]
\end{proposition}


\section{条件期望的计算}

\subsection{离散条件}

如果 $Y$ 是值在可数空间 $E$ 中的随机变量，令 $X\in L^1(\Omega,\mathcal{A},\mathbb{P})$。
那么我们有
\[
  \mathbb{E}[X|Y]=\varphi(Y),  
\]
其中 $y\in E$ 且 $\mathbb{P}(Y=y)>0$ 的时候有
\[
  \varphi(y)=\frac{\mathbb{E}[X\indicator{\{Y=y\}}]}{\mathbb{P}(Y=y)}.
\]

\subsection{带有密度的随机变量}

令 $X,Y$ 分别是值在 $\mathbb{R}^m$ 和 $\mathbb{R}^n$ 中的随机变量，
假设 $(X,Y)$ 有相对于 Lebesgue 测度的密度，记为 $p(x,y)$。
那么对于任意 Borel 可测函数 $f:\mathbb{R}^m\times \mathbb{R}^n\to \mathbb{R}_+$，有
\[
  \mathbb{E}[f(X,Y)]=\int_{\mathbb{R}^m\times \mathbb{R}^n}
  f(x,y)p(x,y)\d x\d y.  
\]
注意此时 $Y$ 有密度
\[
  q(y)=\int_{\mathbb{R}^m}p(x,y)\d x.
\]

令 $h:\mathbb{R}^m\to \mathbb{R}_+$ 是可测函数，我们计算
$\mathbb{E}[h(X)|Y]$。对于任意可测函数 $g:\mathbb{R}^n\to \mathbb{R}_+$，
我们有
\begin{align*}
  \mathbb{E}[h(X)g(Y)]&=\int_{\mathbb{R}^m\times \mathbb{R}^n}
  h(x)g(y)p(x,y)\d x\d y\\
  &=\int_{\mathbb{R}^n}\left(\int_{\mathbb{R}^m}h(x)p(x,y)\d x\right)g(y)\d y\\
  &=\int_{\mathbb{R}^n}\left(\int_{\mathbb{R}^m}h(x)p(x,y)\d x\right)
  g(y)\indicator{\{q(y)>0\}}\d y,
\end{align*}
最后一个等式是因为若 $y$ 使得 $q(y)=0$，那么对于 $x$ 而言几乎处处有 $p(x,y)=0$，
所以 $\int h(x)p(x,y)\d x=0$。于是 
\begin{align*}
  \mathbb{E}[h(X)g(Y)]&=\int_{\mathbb{R}^n}
  \frac{\int_{\mathbb{R}^m}h(x)p(x,y)\d x}{q(y)}
  g(y)q(y)\indicator{\{q(y)>0\}}\d y\\
  &=\int_{\mathbb{R}^n}\varphi(y)g(y)q(y)\indicator{\{q(y)>0\}}\d y\\
  &=\mathbb{E}[\varphi(Y)g(Y)],
\end{align*}
其中
\[
  \varphi(y)=\begin{dcases}
    \frac{1}{q(y)}\int_{\mathbb{R}^m}h(x)p(x,y)\d x & q(y)>0,\\
    h(0) & q(y)=0.
  \end{dcases}  
\]

由于 $g$ 的任意性，根据 \autoref{prop:sigmaX-measurable}，这就表明
对于每个有界的 $\sigma^{-1}(Y)$-可测的实值随机变量 $Z$ 有
\[
  \mathbb{E}[h(X)Z]=\mathbb{E}[\varphi(Y)Z],  
\]
即
\[
  \mathbb{E}[h(X)|Y]=\varphi(Y).  
\]
故我们得到了下面的命题。

\begin{proposition}
  对于每个 $y\in \mathbb{R}^n$，令 $\nu(y,\d x)$ 为
  $\mathbb{R}^m$ 上的概率测度，定义为
  \[
    \nu(y,\d x)=\begin{dcases}
      \frac{1}{q(y)}p(x,y)\d x & q(y)>0,\\
      \delta_0(\d x) & q(y)=0,
    \end{dcases}  
  \]
  那么对于任意可测函数 $h:\mathbb{R}^m\to \mathbb{R}_+$，我们有
  \[
    \mathbb{E}[h(X)|Y]=\int h(x)\nu(Y,\d x).  
  \]
\end{proposition}

对于使得 $q(y)>0$ 的 $y$，我们有
\[
  \mathbb{E}[h(X)|Y=y]=\int h(x)\nu(y,\d x)
  =\frac{1}{q(y)}\int h(x)p(x,y)\d x,  
\]
我们通常说
\[
  x\mapsto\frac{p(x,y)}{q(y)}  
\]
是已知 $Y=y$ 下 $X$ 的条件密度函数。

\section{转移概率和条件分布}

\begin{definition}
  令 $(E,\mathcal{E})$ 和 $(F,\mathcal{F})$ 是两个可测空间，
  $E$ 到 $F$ 的一个\emph{转移概率}指的是映射
  \[
    \nu:E\times \mathcal{F}\to [0,1],  
  \]
  其满足：
  \begin{enumerate}
    \item 对于每个 $x\in E$，$A\mapsto \nu(x,A)$ 是
    $(F,\mathcal{F})$ 上的概率测度。
    \item 对于每个 $A\in \mathcal{F}$，$x\mapsto \nu(x,A)$
    是 $\mathcal{E}$-可测的。
  \end{enumerate}
\end{definition}

从直观上，每固定一个“起点” $x\in E$，概率测度 $\nu(x,\cdot)$
给出了一种随机的选择一个“到达点” $y\in F$ 的方法，这个概念将在
Markov 链中发挥重要作用。

\begin{definition}
  令 $X$ 和 $Y$ 分别是值在 $(E,\mathcal{E})$ 和 $(F,\mathcal{F})$
  中的随机变量。如果 $E$ 到 $F$ 的转移概率 $\nu$ 使得：
  对于任意 $F$ 上的非负可测函数 $h$，有
  \[
    \mathbb{E}[h(Y)|X]=\int\nu(X,\d y) h(y),\quad 
    \alsu{},  
  \]
  那么我们说 $\nu$ 是已知 $X$ 下 $Y$ 的条件分布。
\end{definition}

根据定义，如果 $\nu$ 是已知 $X$ 下 $Y$ 的条件分布，那么对于每个
$A\in \mathcal{F}$，有
\[
  \mathbb{P}(Y\in A|X)=\mathbb{E}[\indicator{\{Y\in A\}}|X]
  =\nu(X,A),\quad \alsu{}
\]
也可以写为对于任意 $x\in E$，有
\[
  \mathbb{P}(Y\in A| X=x)=\nu(x,A).  
\]

\part{随机过程}

\chapter{Markov 链}

\section{定义和首要性质}

在本章中，$E$ 表示一个有限或者可数空间，配备 $\sigma$-域
$\mathcal{P}(E)$。$E$ 上的随机矩阵指的是一族实数 
$(Q(x,y))_{(x,y)\in E\times E}$，其满足：
\begin{enumerate}
  \item 对于任意 $x,y\in E$，$0\leq Q(x,y)\leq 1$；
  \item 对于每个 $x\in E$，$\sum_{y\in E}Q(x,y)=1$。
\end{enumerate}

这个概念等价于从 $E$ 到 $E$ 的转移概率。实际上，如果我们令
\[
  \nu(x,A)=\sum_{y\in A}Q(x,y),\quad x\in E,A\subseteq E,  
\]
那么 $\nu$ 就是一个从 $E$ 到 $E$ 的转移概率。反之，给定一个
转移概率 $\nu$，定义 $Q(x,y)=\nu(x,\{y\})$，这就给出了 
$E$ 上的一个随机矩阵。

对于每个 $n\geq 1$，我们定义 $Q_n=Q^n$ 为通常的矩阵乘法：
定义 $Q_1=Q$，然后递归定义
\[
  Q_{n+1}(x,y)=\sum_{z\in E}Q_n(x,z)Q(z,y).  
\]
不难验证 $Q_n$ 仍然是 $E$ 上的一个随机矩阵。我们同时定义
$Q_0(x,y)=\indicator{\{x=y\}}$（类似单位阵）。
那么对于任意 $m,n\geq 0$，我们有 $Q_{m+n}=Q_mQ_n$：
\[
  Q_{m+n}(x,y)=\sum_{z\in E}Q_m(x,z)Q_n(z,y).  
\]

对于每个函数 $f:E\to \mathbb{R}_+$，用 $Qf$ 表示 $E$
上的函数，满足
\[
  Qf(x)=\sum_{y\in E}Q(x,y)f(y),  
\]
取值在 $[0,\infty]$ 中。如果 $\nu$ 是 $E$ 上的测度，我们
同时定义
\[
  \nu Q(y)=\sum_{x\in E}\nu(x)Q(x,y),\quad y\in E.  
\]

\begin{definition}
  令 $Q$ 是 $E$ 上的随机矩阵，$(X_n)_{n\in \mathbb{Z}_+}$
  是定义在 $(\Omega,\mathcal{A},\mathbb{P})$ 上值在 $E$ 中的随机过程。
  如果对于每个 $n\geq 0$，已知 $(X_0,X_1,\dots,X_n)$ 下的
  $X_{n+1}$ 的条件分布是 $Q(X_n,\cdot)$，那么 
  我们说 $(X_n)_{n\in \mathbb{Z}_+}$ 是具有转移矩阵 $Q$
  是 Markov 链。这等价于说对于每个 $x_0,\dots,x_n,y\in E$
  使得 $\mathbb{P}(X_0=x_0,\dots,X_n=x_n)>0$，都有
  \[
    \mathbb{P}(X_{n+1}=y|X_0=x_0,\dots,X_n=x_n)=Q(x_n,y).  
  \]
\end{definition}

已知 $(X_0,X_1,\dots,X_n)$ 下的 $X_{n+1}$ 的条件分布是 $Q(X_n,\cdot)$ 还意味着
对于每个 $y\in E$，有
\[
  \mathbb{P}(X_{n+1}=y|X_0,\dots,X_n)=Q(X_n,y).
\]
注意这是随机变量的等式。

利用 \autoref{prop:nested sigma field}，对于 $\{0,1,\dots,n-1\}$ 的任意子集
$\{i_1,\dots,i_k\}$，我们有
\begin{align*}
  &\hphantom{={}}\mathbb{P}(X_{n+1}=y|X_{i_1},\dots,X_{i_k},X_n)\\
  &=\mathbb{E}\bigl[\mathbb{P}(X_{n+1}=y|X_{0},X_1,\dots,X_n)\bigm| X_{i_1},\dots,X_{i_k},X_n\bigr]\\
  &=\mathbb{E}[Q(X_{n},y)|X_{i_1},\dots,X_{i_k},X_n]\\
  &=Q(X_n,y)
\end{align*}
特别地，有
\[
  \mathbb{P}(X_{n+1}=y|X_n)=Q(X_n,y).
\]
这等价于，对于每个使得 $\mathbb{P}(X_n=x)>0$ 的 $x\in E$，有
\[
  \mathbb{P}(X_{n+1}=y|X_n=x)=Q(x,y).
\]
这个式子提供了一种直观理解，即如果 Markov 链在 $n$ 时间处于点 $x\in E$ 处，那么
可以根据概率测度 $Q(x,\cdot)$ 衡量其在 $n+1$ 时间到达点的位置。

\begin{remark}
  \mbox{}
  \begin{enumerate}
    \item 对于一般的随机过程 $(X_n)_{n\in \mathbb{Z}_+}$，已知 $(X_0,X_1,\dots,X_n)$
    下 $X_{n+1}$ 的条件分布可以写为 $\nu((X_0,X_1,\dots,X_n),\cdot)$ 的形式，其中
    $\nu$ 表示从 $E^{n+1}$ 到 $E$ 的转移概率，此时条件分布依赖于所有 $X_0,X_1,\dots,X_n$
    而不仅仅是 $X_n$。而 Markov 链的定义要求已知 $(X_0,X_1,\dots,X_n)$
    下 $X_{n+1}$ 的条件分布仅仅依赖于 $X_n$，这被称为\emph{Markov 属性}：
    为了预测 $X_{n+1}$，过去的所有 $(X_0,X_1,\dots,X_n)$ 的知识并不能提供比 $X_n$
    更多的信息。  
    \item 函数 $Q(x,\cdot)$ 给出了在不依赖 $n$ 的情况下，已知 $X_n=x$ 下 $X_{n+1}$
    的条件分布。这就是“转移机制”的\emph{时齐性}。人们还可以考虑非齐次 Markov 链，
    其中时间 $n$ 和 $n + 1$ 之间的转移机制取决于 $n$，但在本课程中我们仅考虑齐次 Markov 链。
  \end{enumerate}
\end{remark}

\begin{proposition}\label{prop:law of X0 to Xn}
  一个值在 $E$ 中的随机过程 $(X_n)_{n\in \mathbb{Z}_+}$ 是具有转移矩阵 $Q$ 的 Markov 链当且仅当
  对于每个 $n\geq 0$ 和 $x_0,x_1,\dots,x_n\in E$，我们有
  \[
    \mathbb{P}(X_0=x_0,X_1=x_1,\dots,X_n=x_n)=\mathbb{P}(X_0=x_0)
    Q(x_0,x_1)\cdots Q(x_{n-1},x_n).
  \]
\end{proposition}
\begin{proof}
  若 $(X_n)_{n\in \mathbb{Z}_+}$ 是具有转移矩阵 $Q$ 的 Markov 链，那么依据
  \begin{align*}
    &\mathbb{P}(X_0=x_0,X_1=x_1,\dots,X_n=x_n,X_{n+1}=x_{n+1})\\
    &=\mathbb{P}(X_0=x_0,\dots,X_n=x_n)\mathbb{P}(X_{n+1}=x_{n+1}|X_0=x_0,\dots,X_n=x_n)
  \end{align*}
  进行归纳即可。

  反之，假设上式成立，那么
  \begin{align*}
    &\mathbb{P}(X_{n+1}=y|X_0=x_0,\dots,X_n=x_n)\\
    &=\frac{\mathbb{P}(X_0=x_0,\dots,X_n=x_n,X_{n+1}=y)}{\mathbb{P}(X_0=x_0,\dots,X_n=x_n)}
    =Q(x_n,y),
  \end{align*}
  即 $(X_n)_{n\in \mathbb{Z}_+}$ 是具有转移矩阵 $Q$ 的 Markov 链。
\end{proof}

\begin{remark}
  这表明对于 Markov 链 $(X_n)_{n\in \mathbb{Z}_+}$，$(X_0,X_1,\dots,X_n)$
  的分布完全由初始分布和转移矩阵 $Q$ 确定。
\end{remark}

\begin{proposition}
  $(X_n)_{n\in \mathbb{Z}_+}$ 是具有转移矩阵 $Q$ 的 Markov 链。
  \begin{enumerate}
    \item 对于每个 $n\geq 0$ 和可测函数 $f:E\to \mathbb{R}_+$，
    \[
      \mathbb{E}[f(X_{n+1})|X_0,X_1,\dots,X_n]=\mathbb{E}[f(X_{n+1})|X_n]=Qf(X_n).
    \]
    更一般地，对于 $\{0,1,\dots,n-1\}$ 的任意子集 $\{i_1,\dots,i_k\}$，我们有
    \[
      \mathbb{E}[f(X_{n+1})|X_{i_1},\dots,X_{i_k},X_n]=Qf(X_n).
    \]
    \item 对于每个 $n\geq 0$，$p\geq 1$ 以及 $y_1,\dots,y_p\in E$，有
    \begin{align*}
      &\mathbb{P}(X_{n+1}=y_1,\dots,X_{n+p}=y_p|X_0,\dots,X_n)\\
      &=Q(X_n,y_1)Q(y_1,y_2)\cdots Q(y_{p-1},y_p).
    \end{align*}
    因此，有
    \[
      \mathbb{P}(X_{n+p}=y_p|X_n)=\mathbb{P}(X_{n+p}=y_p|X_0,\dots,X_n)=
      Q_p(X_n,y_p).
    \]
    如果我们固定 $n\geq 0$，对于每个 $p\in \mathbb{Z}_+$，令 $Y_p=X_{n+p}$，
    那么随机过程 $(Y_p)_{p\in \mathbb{Z}_+}$ 仍然是带有转移矩阵 $Q$ 的 Markov 链。
  \end{enumerate}
\end{proposition}
\begin{proof}
  (1) 注意到 $f(X_{n+1})=\sum_{y\in E}f(y)\indicator{\{X_{n+1}=y\}}$，那么
  \begin{align*}
    \mathbb{E}[f(X_{n+1})|X_0,X_1,\dots,X_n]
    &=\sum_{y\in E}f(y)\mathbb{P}(X_{n+1}=y|X_0,X_1,\dots,X_n)\\
    &=\sum_{y\in E}f(y)Q(X_n,y)\\
    &=Qf(X_n).
  \end{align*}
  对于 $\{0,1,\dots,n-1\}$ 的任意子集 $\{i_1,\dots,i_k\}$，我们有
  \begin{align*}
    &\mathbb{E}[f(X_{n+1})|X_{i_1},\dots,X_{i_k},X_n]\\
    &=\mathbb{E}\bigl[\mathbb{E}[f(X_{n+1})|X_0,X_1,\dots,X_n]\bigm| X_{i_1},\dots,X_{i_k},X_n\bigr]\\
    &=\mathbb{E}[Qf(X_n)|X_{i_1},\dots,X_{i_k},X_n]\\
    &=Qf(X_n).
  \end{align*}

  (2) 根据 \autoref{prop:law of X0 to Xn}，有
  \begin{align*}
    &\mathbb{P}(X_{n+1}=y_1,\dots,X_{n+p}=y_p|X_0=x_0,\dots,X_n=x_n)\\
    &=\frac{\mathbb{P}(X_0=x_0)Q(x_0,x_1)\cdots Q(x_n,y_1)\cdots Q(y_{p-1},y_p)}{
      \mathbb{P}(X_0=x_0)Q(x_0,x_1)\cdots Q(x_{n-1},x_n)
    }\\
    &=Q(x_n,y_1)Q(y_1,y_2)\cdots Q(y_{p-1},y_p),
  \end{align*}
  即 
  \begin{align*}
    &\mathbb{P}(X_{n+1}=y_1,\dots,X_{n+p}=y_p|X_0,\dots,X_n)\\
    &=Q(X_n,y_1)Q(y_1,y_2)\cdots Q(y_{p-1},y_p).
  \end{align*}

  对于 $p=2$ 的情况，有
  \begin{align*}
    \mathbb{P}(X_{n+2}=y_2|X_0,\dots,X_n)
    &=\sum_{y_1\in E}\mathbb{P}(X_{n+1}=y_1,X_{n+2}=y_2|X_0,\dots,X_n)\\
    &=\sum_{y_1\in E} Q(X_n,y_1)Q(y_1,y_2)\\
    &=Q_2(X_n,y_2),
  \end{align*}
  一般的情况由此归纳即可。于是
  \begin{align*}
    \mathbb{P}(X_{n+p}=y_p|X_n)
    &=\mathbb{E}\bigl[\mathbb{P}(X_{n+p}=y_p|X_0,\dots,X_n)\bigm| X_n\bigr]\\
    &=\mathbb{E}[Q_p(X_n,y_p)|X_n]=Q_p(X_n,y_p).
  \end{align*}

  最后我们验证 $(Y_p)_{p\in \mathbb{Z}_+}$ 是带有转移矩阵 $Q$ 的 Markov 链。
  根据定义，有
  \begin{align*}
    &\mathbb{P}(Y_{p+1}=y_{p+1}|Y_0,\dots,Y_p)\\
    &=\mathbb{P}(X_{n+p+1}=y_{p+1}|X_n,\dots,X_{n+p})\\
    &=\mathbb{E}\bigl[\mathbb{P}(X_{n+p+1}=y_{p+1}|X_0,\dots,X_{n+p})\bigm| X_n,\dots,X_{n+p}\bigr]\\
    &=\mathbb{E}[Q(X_{n+p},y_{p+1})|X_n,\dots,X_{n+p}]\\
    &=Q(X_{n+p},y_{p+1})=Q(Y_p,y_{p+1}),
  \end{align*}
  这就表明 $(Y_p)_{p\in \mathbb{Z}_+}$ 是带有转移矩阵 $Q$ 的 Markov 链。
\end{proof}


\section{例子}

\subsection{$\mathbb{Z}^d$ 上的随机游走}


\section{典范的 Markov 链}

在本节中，我们解释如何对概率空间（和随机过程）进行典范的选择，以获得具有给定转移矩阵的 Markov 链。
这与前面的章节形成对比，前面的章节没有指定潜在的概率空间。在 Markov 链的背景下，这种典范的选择
将有几个优点。特别是，它将使我们能够同时考虑给定的 Markov 链和所有可能的初始点。

\begin{proposition}
  令 $Q$ 是 $E$ 上的随机矩阵，我们可以找到一个概率空间 $(\Omega,\mathcal{A},\mathbb{P})$ 使得对于
  每个 $x\in E$，都可以构建一个带有转移矩阵 $Q$ 的 Markov 链 $(X_n^x)_{n\in \mathbb{Z}_+}$ 且
  $X_0^x=x$。
\end{proposition}

下面我们解释这个概率空间的选择，我们令
\[
  \mat\Omega=E^{\mathbb{Z}_+},
\]
即 $\mat\Omega$ 的元素形如 $\omega=(\omega_0,\omega_1,\omega_2,\dots)$。定义坐标映射
$\mat X_n$ 为 $\mat X_n(\omega)=\omega_n$。我们给 $\mat\Omega$ 配备使得所有坐标映射
$\mat X_n$ 都可测的最小的 $\sigma$-域，记为 $\mathfrak{F}$，等价地说，
$\mathfrak{F}$ 由所有的柱集生成：
\[
  \{x_0\}\times\cdots\times\{x_n\}\times E\times E\times \cdots,
\]
其中 $n\in \mathbb{Z}_+,x_0,\dots,x_n\in E$。

\begin{lemma}
  令 $(G,\mathcal{G})$ 是可测空间，映射$\psi:G\to \mat\Omega$，那么
  $\psi$ 可测当且仅当 $\mat X_n\circ\psi$ 可测。
\end{lemma}

\begin{theorem}
  令 $Q$ 是 $E$ 上的随机矩阵，对于每个 $x\in E$，存在唯一的 $(\mat\Omega,\mathfrak F)$ 上
  的概率测度 $\matup P_x$ 使得坐标过程 $(\mat X_n)_{n\in \mathbb{Z}_+}$ 是带有
  转移矩阵 $Q$ 的 Markov 链并且 $\matup P_x(\mat X_0=x)=1$。
\end{theorem}
\begin{remark}
  我们将说在概率空间 $(\mat\Omega,\mathfrak F,\matup P_x)$ 上的坐标过程
  $(\mat X_n)_{n\in \mathbb{Z}_+}$ 是具有转移矩阵 $Q$ 和初值 $x$ 的\emph{典范 Markov 链}。
\end{remark}

\begin{remark}\label{rmk:canonical Markov}
  令 $(Y_n)_{n\in \mathbb{Z}_+}$ 是概率测度 $\mathbb{P}$ 下具有转移矩阵 $Q$ 的 Markov 链
  且 $Y_0=x$。那么对于 $\mat\Omega=E^{\mathbb{Z}_+}$ 的任意可测子集 $B$，有
  \[
    \mathbb{P}\bigl((Y_n)_{n\in \mathbb{Z}_+}\in B\bigr)=\matup P_x(B).
  \]
  事实上，当 $B$ 是柱集（cylinder set）时，这个等式成立，然后依据单调类给出一般情况。
  这个等式表明，我们后面为典范 Markov 链建立的所有结果都可以转移到具有相同转移矩阵的任何
  Markov 链上（无论它是在哪个概率空间上定义的）。
\end{remark}

\section{状态分类}

从现在开始，除非另有说明，否则我们将考虑上一节中针对 $E$ 上给定随机矩阵 $Q$ 引入的典范 Markov 链。
如 \autoref{rmk:canonical Markov} 所述，我们可以将得出的所有结果都转移到
在任何概率空间上定义的具有相同转移矩阵的 Markov 链。

回顾记号
\[
  H_x=\inf\{n\geq 1| \mat X_n=x\}, N_x=\sum_{n=0}^\infty \indicator{\{\mat X_n=x\}}.
\]
在 Markov 链中，$H_x$ 可以解释为状态第一次经过点 $x$ 时需要的步数，
$N_x$ 可以解释为状态经过点 $x$ 的次数。

\begin{proposition}\label{prop:recurrent and transient}
  令 $x\in E$，那么
  \begin{itemize}
    \item 要么 $\matup P_x(H_x<\infty)=1$，此时
    \[
      N_x=\infty,\ \alsu{\matup P_x}
    \]
    这种情况下 $x$ 被称为\emph{常返的}。
    \item 要么 $\matup P_x(H_x<\infty)<1$，此时
    \[
      N_x<\infty,\ \alsu{\matup P_x}
    \]
    更准确地，对于每个 $k\geq 1$ 有 $\matup P_x(N_x=k)=\matup P_x(H_x=\infty)\matup P_x(H_x<\infty)^{k-1}$，
    并且 $\matup E_x[N_x]=1/\matup P_x(H_x=\infty)<\infty$，在这种情况下 $x$
    被称为是\emph{暂留的}。
  \end{itemize}
\end{proposition}
\begin{remark}
  直观上来说，$\matup P_x(H_x<\infty)=1$ 的情况表明如果状态几乎肯定能够经过点 $x$，那么
  其几乎肯定能够无数次经过点 $x$。$\matup P_x(H_x<\infty)<1$ 的情况表明
  如果状态不一定能经过点 $x$，那么其经过点 $x$ 的次数几乎肯定是有限次，且期望也是有限次。
\end{remark}

\begin{definition}
  Markov 链的潜在核定义为 $E\times E$ 上的函数 
  \[
    U(x,y)=\matup E_x[N_y].
  \]
\end{definition}

注意到 $U(x,y)>0$ 当且仅当从 $x$ 出发的链能够到达 $y$ 的概率是正的。

\begin{proposition}
  \mbox{}
  \begin{enumerate}
    \item 对于每个 $x,y\in E$，有
    \[
      U(x,y)=\sum_{n=0}^\infty Q_n(x,y).  
    \]
    \item $U(x,x)=\infty$ 当且仅当 $x$ 是常返的。
    \item 对于每个 $x,y\in E$ 且 $x\neq y$，有
    \[
      U(x,y)=\matup P_x(H_y<\infty) U(y,y).  
    \]
    因此，如果 $y$ 是暂留的，那么对于每个 $x\in E$，
    我们有 $\matup P_x(N_y<\infty)=1$。
  \end{enumerate}
\end{proposition}
\begin{proof}
  (1) 直接计算可知
  \[
    U(x,y)=\matup E_x\left[
      \sum_{n=0}^\infty \indicator{\{\mat X_n=y\}}
    \right]  =\sum_{n=0}^\infty \matup P_x(\mat X_n=y)
    =\sum_{n=0}^\infty Q_n(x,y).
  \]

  (2) 根据 $U$ 的定义，我们有
  $U(x,x)=\infty$ 当且仅当 $\matup P_x(N_x=\infty)=1$，
  即 $x$ 是常返的。

  (3) 
\end{proof}

\begin{remark}
  这个命题告诉我们
  \[
    U(x,y)=\sum_{n=0}^\infty Q_n(x,y)=\sum_{n=0}^\infty
    \matup P_x(X_{m+n}=y|X_m=x),
  \]
  所以 $U(x,y)>0$ 当且仅当存在某个 $n$ 使得 $\matup P_x(X_{m+n}=y|X_m=x)>0$。
  有些教材会把 $\matup P_x(X_{m+n}=y|X_m=x)$ 记为 $p_{xy}^{(n)}$，
  称作\emph{$n$ 步转移概率}。若 $U(x,y)>0$（等价地说，存在
  $n\geq 0$ 使得 $p_{xy}^{(n)}>0$），那么我们说 $x$ \emph{可达}
  $y$，记为 $x\to y$。如果同时有 $y\to x$，那么我们说 
  $x$ 和 $y$ \emph{互通}，记为 $x\leftrightarrow y$。
  不难验证互通是一个等价关系。
\end{remark}

我们记所有常返点的集合为 $R$。

\begin{lemma}
  假设 $x\in R$ 且 $y\in E \smallsetminus\{x\}$ 使得 $U(x,y)>0 \ (x\to y)$，
  那么 $y\in R$ 且 $\matup P_y(H_x<\infty)=1$，因此 $U(y,x)>0\ (y\to x)$。
\end{lemma}





\end{document}
